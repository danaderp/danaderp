---
layout: distill
title: doCode
description: Toward a Causal Understanding of Neural Language Models for Code Generation. A preliminary research in formalizing causal inference for deep learning interpretability for SE.
giscus_comments: true
date: 2022-12-27

authors:
  - name: David N. Palacio
    url: "https://github.com/danaderp"
    affiliations:
      name: SEMERU, William & Mary
  - name: David N. Palacio
    url: "https://github.com/danaderp"
    affiliations:
      name: SEMERU, William & Mary

bibliography: 2022-12-27-docode.bib

# Optionally, you can add a table of contents to your post.
# NOTES:
#   - make sure that TOC names match the actual section names
#     for hyperlinks within the post to work correctly.
#   - we may want to automate TOC generation in the future using
#     jekyll-toc plugin (https://github.com/toshimaru/jekyll-toc).
toc:
  - name: Introduction
    # if a section has subsections, you can add them as follows:
    # subsections:
    #   - name: Example Child Subsection 1
    #   - name: Example Child Subsection 2
  #- name: Citations


# Below is an example of injecting additional post-specific styles.
# If you use this post as a template, delete this _styles block.
_styles: >
  .fake-img {
    background: #bbb;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
    margin-bottom: 12px;
  }
  .fake-img p {
    font-family: monospace;
    color: white;
    text-align: left;
    margin: 12px 0;
    text-align: center;
    font-size: 16px;
  }

---

## Introduction

The combination of large amounts of freely available code-related data, which can be mined from open source repositories, and ever-more sophisticated  Neural Language Model  (NLM) architectures have fueled the development of Software Engineering (SE) tools with increasing effectiveness. NLMs for code have (seemingly) illustrated promising performance across a range of different SE tasks~\cite{Watson:ICSE20,White:MSR15,ciniselli2021empirical,Mastropaolo2021StudyingTasks}. In particular, \textit{code generation} has been an important area of SE research for decades, enabling tools for downstream tasks such as code completion~\cite{MSR-Completion}, program repair~\cite{Chen2019sequencer}, and test case generation~\cite{Watson:ICSE20}. In addition, industry interest in leveraging NLMs for code generation has also grown as evidenced by tools just as Microsoft's IntelliCode \cite{intellicode}, Tabnine \cite{tabnine}, OpenAI's Codex \cite{openai_codex}, and GitHub's Copilot \cite{github_copilot}. Given the prior popularity of code completion engines within IDEs~\cite{murphy2006ide}, and the pending introduction of, and investment in commercial tools, NLMs for code generation will almost certainly be used to help build production software systems in the near future, if they are not already being used. 


***



***

***
