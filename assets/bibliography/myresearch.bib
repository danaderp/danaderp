@article{mastropaolo_using_2023,
	title = {Using Transfer Learning for Code-Related Tasks},
	volume = {49},
	issn = {0098-5589, 1939-3520, 2326-3881},
	url = {https://ieeexplore.ieee.org/document/9797060/},
	doi = {10.1109/TSE.2022.3183297},
	abstract = {Deep learning ({DL}) techniques have been used to support several code-related tasks such as code summarization and bug-ﬁxing. In particular, pre-trained transformer models are on the rise, also thanks to the excellent results they achieved in Natural Language Processing ({NLP}) tasks. The basic idea behind these models is to ﬁrst pre-train them on a generic dataset using a self-supervised task (e.g., ﬁlling masked words in sentences). Then, these models are ﬁne-tuned to support speciﬁc tasks of interest (e.g., language translation). A single model can be ﬁne-tuned to support multiple tasks, possibly exploiting the beneﬁts of transfer learning. This means that knowledge acquired to solve a speciﬁc task (e.g., language translation) can be useful to boost performance on another task (e.g., sentiment classiﬁcation). While the beneﬁts of transfer learning have been widely studied in {NLP}, limited empirical evidence is available when it comes to code-related tasks. In this paper, we assess the performance of the Text-To-Text Transfer Transformer (T5) model in supporting four different code-related tasks: (i) automatic bug-ﬁxing, (ii) injection of code mutants, (iii) generation of assert statements, and (iv) code summarization. We pay particular attention in studying the role played by pre-training and multi-task ﬁne-tuning on the model’s performance. We show that (i) the T5 can achieve better performance as compared to state-of-the-art baselines; and (ii) while pre-training helps the model, not all tasks beneﬁt from a multi-task ﬁne-tuning.},
	pages = {1580--1598},
	number = {4},
	journaltitle = {{IIEEE} Trans. Software Eng.},
	author = {Mastropaolo, Antonio and Cooper, Nathan and Palacio, David Nader and Scalabrino, Simone and Poshyvanyk, Denys and Oliveto, Rocco and Bavota, Gabriele},
	urldate = {2023-07-19},
	date = {2023-04-01},
	langid = {english},
	file = {Mastropaolo et al. - 2023 - Using Transfer Learning for Code-Related Tasks.pdf:C\:\\Users\\David\\Zotero\\storage\\VAYM2QF4\\Mastropaolo et al. - 2023 - Using Transfer Learning for Code-Related Tasks.pdf:application/pdf},
	abbr={TSE},
}


@article{palacio_learning_2019,
	title = {Learning to Identify Security-Related Issues Using Convolutional Neural Networks},
	html = {http://arxiv.org/abs/1908.00614},
	abstract = {Software security is becoming a high priority for both large companies and start-ups alike due to the increasing potential for harm that vulnerabilities and breaches carry with them. However, attaining robust security assurance while delivering features requires a precarious balancing act in the context of agile development practices. One path forward to help aid development teams in securing their software products is through the design and development of security-focused automation. Ergo, we present a novel approach, called {SecureReqNet}, for automatically identifying whether issues in software issue tracking systems describe security-related content. Our approach consists of a two-phase neural net architecture that operates purely on the natural language descriptions of issues. The ﬁrst phase of our approach learns high dimensional word embeddings from hundreds of thousands of vulnerability descriptions listed in the {CVE} database and issue descriptions extracted from open source projects. The second phase then utilizes the semantic ontology represented by these embeddings to train a convolutional neural network capable of predicting whether a given issue is securityrelated. We evaluated {SecureReqNet} by applying it to identify security-related issues from a dataset of thousands of issues mined from popular projects on {GitLab} and {GitHub}. In addition, we also applied our approach to identify security-related requirements from a commercial software project developed by a major telecommunication company. Our preliminary results are encouraging, with {SecureReqNet} achieving an accuracy of 96\% on open source issues and 71.6\% on industrial requirements.},
	publisher = {{arXiv}},
	author = {Palacio, David N. and {McCrystal}, Daniel and Moran, Kevin and Bernal-Cárdenas, Carlos and Poshyvanyk, Denys and Shenefiel, Chris},
	urldate = {2023-07-19},
	date = {2019-08-05},
	eprint = {1908.00614 [cs]},
	keywords = {Computer Science - Software Engineering},
  	abbr = {ICSME},
  	code = {https://github.com/WM-SEMERU/SecureReqNet}
}